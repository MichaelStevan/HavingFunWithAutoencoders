{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### README \n",
    "\n",
    "This exercise shows what a student would be able to accomplish at the end of the proposed course outline.\n",
    "\n",
    "However this exercise is a bit longer than what you'd usually find in a DataCamp coding section alone, the building of this model would expand throughout the last section of the last chapter as a series of exercises. \n",
    "\n",
    "That's why this last section of the last chapter consists on getting an intuition on autoencoders at the same time you build one and realize why the keras functional API can be useful for slightly more\n",
    "complicated model architectures.\n",
    "\n",
    "It would probably be one of the most complex exercises in the course.\n",
    "\n",
    "- This exercise is based on a blog post by Keras creator Fran√ßois Chollet, I've slightly modified it, commented it and simplified it in a way I found easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A final Challenge: Build an Autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to use all the knowledge adquired during the course to complete a final feat: **Building your own MNIST Autoencoder**.\n",
    "\n",
    "This is not an easy challenge !\n",
    "To achieve it, we will take advantage of the **Keras functional API**.\n",
    "\n",
    "But, what's is an autoencoder?, you may ask.\n",
    "\n",
    "An autoencoder is a neural network architecture that will try to produce an output which matches its input as closely as possible.\n",
    "\n",
    "This objective, along with a series of layer/s of diminishing number of nodes leads to the original input being compressed into a lower dimentional space (encoded), and them decoded back to its original shape.\n",
    "\n",
    "So we will approach this problem by building two models:\n",
    "\n",
    "- An encoder model which encodes our 784 pixel MNIST images. \n",
    "\n",
    "- A decoder model that takes the encoded output of the previous encoder as an input and transforms it back to its original digit form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Define an input for a flattened 784 pixels \n",
    "# value (from our MNIST images)\n",
    "input_img = Input(shape=(___,))\n",
    "\n",
    "# The size of the encoded representations of our numbers\n",
    "# will be 32, that is 24.5 times smaller than the original images!\n",
    "encoding_dim = 32\n",
    "\n",
    "# Define encoded as a Dense layer that will learn the encoded representation of our digits.\n",
    "# The number of nodes is encoding_dim and it receives the input_img as an input. \n",
    "encoded = Dense(___,activation='relu')(___)\n",
    "\n",
    "# Define decoded as a Dense layer of nodes of size the original number of pixels.\n",
    "# This layer will learn to transform our digits from their encoded representation back\n",
    "# to their original size.\n",
    "decoded = Dense(___,activation=\"sigmoid\")(____)\n",
    "\n",
    "# Define a model that maps our original image input to \n",
    "# its encoded representation\n",
    "encoder = Model(input_img,____)\n",
    "\n",
    "# The autoencoder model will map our input to it's reconstruction (decoded state).\n",
    "autoencoder = Model(____,____)\n",
    "\n",
    "# We compile our autoencoder with an adadelta optimizer and binary_crossentropy,\n",
    "# since we are making predictions per pixel.\n",
    "autoencoder.compile(_____,_____)\n",
    "\n",
    "# Take a look at our autoencoder model structure.\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Student wouldn't see this code which prepares the MNIST dataset\n",
    "# to be used by the previously built models.\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(X_train,_),(X_test,_) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape MNIST so that it can be used by our models.\n",
    "X_train = X_train.astype('float32')/255.\n",
    "X_test = X_test.astype('float32')/255.\n",
    "X_train =  X_train.reshape((len(X_train),np.prod(X_train.shape[1:])))\n",
    "X_test =  X_test.reshape((len(X_test),np.prod(X_test.shape[1:])))\n",
    "\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST have already been imported for you and split into X_train and\n",
    "# X_test datasets.\n",
    "\n",
    "# Fit your autoencoder, remember this time X_train is both\n",
    "# your input and output. Use 50 epochs with a batch_size of 256, since our training \n",
    "# set is quite large. Make use of X_test as validation data for your model.\n",
    "\n",
    "autoencoder.fit(___,___,\n",
    "               epochs = ____,\n",
    "               batch_size = ____,\n",
    "               shuffle=True,\n",
    "               validation_data=(___,___))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know want to obtain both our encoded and our decoded images.\n",
    "# And display them, to asses how good our model was.\n",
    "\n",
    "# In order to do so we can proceed by doing the following:\n",
    "\n",
    "# Use our previously built encoder model to obtain the encoded version \n",
    "# of our images.\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "\n",
    "# We do not have a decoder model to decodify the images we just encoded,\n",
    "# but creating one is simple with the functional API:\n",
    "\n",
    "# 1) Select the last layer from our already trained autoencoder model.\n",
    "# This layer already has the learned weights to decode our images, so it's\n",
    "# quite useful for our task at hand.\n",
    "\n",
    "decoder_layer = autoencoder.___[_]\n",
    "\n",
    "# 2) Create and input of shape equal to our encoding_dim.\n",
    "encoded_input = Input(shape=(_____,))\n",
    "\n",
    "# 3) Build our decoder model\n",
    "decoder = Model(encoded_input,decoder_layer(encoded_input))\n",
    "\n",
    "# Take a look at our decoded model structure\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Student wouldn't see this code which is used to plot\n",
    "# the results of the model.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(X_test,decoded_imgs):\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(X_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "##################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to see if our autoencoder is performing correctly.\n",
    "\n",
    "# Use the encoder model to encode X_test images.\n",
    "encoded_imgs = _____.____(___)\n",
    "\n",
    "# Use our decoder model to predict the recently encoded images\n",
    "decoded_imgs = _____.predict(encoded_imgs)\n",
    "\n",
    "# Call plot_results() passing the X_test images and decoded_imgs as parameters \n",
    "# and look at the results !\n",
    "plot_results(___,___)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
